{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bdb7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pytesseract\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef726919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c675dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mj=joblib.load('/Users/rahul/Downloads/IAM_Words/act_model__joblib_10_epochs')\n",
    "cnn=joblib.load('/Users/rahul/Downloads/IAM_Words/DTvsHW_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4201435",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set={'M', \"'\", '/', ')', 'm', 'q', 'k', 'N', '!', ',', 'o', 'W', '+', '#', '0', 'y', 'd', 'j', 'h', 'I', '-', 'Z', 'F', 'Y', 'g', 'P', 'V', 'e', 'z', 'R', '5', 'p', '1', '?', 'x', 'c', 'D', '.', 'C', 'K', 'w', 'v', 'G', '(', 'T', '3', 'S', ':', 'i', 'A', 'E', 'a', 'U', '6', 'b', 't', '*', '9', '8', 'l', '4', ';', 'X', '2', 's', '7', 'r', 'J', 'O', 'Q', 'B', 'n', 'f', '&', 'u', '\"', 'L', 'H'}\n",
    "char_list = sorted(list(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    \"\"\"\n",
    "    Converts image to shape (32, 128, 1) & normalize\n",
    "    \"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    w, h = img.shape\n",
    "\n",
    "    # Aspect Ratio Calculation\n",
    "    new_w = 32\n",
    "    new_h = int(h * (new_w / w))\n",
    "    img = cv2.resize(img, (new_h, new_w))\n",
    "    w, h = img.shape\n",
    "\n",
    "    img = img.astype('float32')\n",
    "\n",
    "    # Converts each to (32, 128, 1)\n",
    "    if w < 32:\n",
    "        add_zeros = np.full((32-w, h), 255)\n",
    "        img = np.concatenate((img, add_zeros))\n",
    "        w, h = img.shape\n",
    "\n",
    "    if h < 128:\n",
    "        add_zeros = np.full((w, 128-h), 255)\n",
    "        img = np.concatenate((img, add_zeros), axis=1)\n",
    "        w, h = img.shape\n",
    "\n",
    "    if h > 128 or w > 32:\n",
    "        dim = (128,32)\n",
    "        img = cv2.resize(img, dim)\n",
    "\n",
    "    img = cv2.subtract(255, img)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "\n",
    "    # Normalize\n",
    "    img = img / 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296067d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.title(\"hand written text prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ba63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_cv2(uploaded_file):\n",
    "    # Convert the uploaded file to an OpenCV image\n",
    "    image = Image.open(uploaded_file)\n",
    "    image_array = np.array(image)\n",
    "    image_cv = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)\n",
    "    return image_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first1(predictable_img):\n",
    "    predictable_array_images=[]\n",
    "    predictable_img2 = process_image(predictable_img)\n",
    "    predictable_array_images.append(predictable_img2)\n",
    "    print(predictable_array_images[0].shape)\n",
    "    bimbon_images = np.array(predictable_array_images)\n",
    "    bimbon_images = tf.expand_dims(bimbon_images, axis=0)\n",
    "    print(bimbon_images[0].shape)\n",
    "    # predict outputs on validation images\n",
    "    prediction = mj.predict(bimbon_images[0])\n",
    "\n",
    "    print(prediction)\n",
    "\n",
    "    # use CTC decoder\n",
    "    decoded = K.ctc_decode(prediction,   \n",
    "                           input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
    "                           greedy=True)[0][0]\n",
    "\n",
    "    out = K.get_value(decoded)\n",
    "    print('out is ',out)\n",
    "\n",
    "    for i, x in enumerate(out):\n",
    "        print(\"predicted text = \", end = '')\n",
    "        S=\"\"\n",
    "        for p in x:\n",
    "            if int(p) != -1:\n",
    "                #print(char_list[int(p)], end = '')\n",
    "                S+=char_list[int(p)]\n",
    "        new_shape = (32, 128)  # Example new shape\n",
    "        reshaped_tensor = tf.reshape(bimbon_images[0], new_shape)\n",
    "        plt.imshow(reshaped_tensor,cmap=plt.cm.gray)\n",
    "        plt.show()\n",
    "        return S\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HWContours(cnts):\n",
    "    x=image.shape[1]\n",
    "    print('x:-',x)\n",
    "    y=image.shape[0]\n",
    "    print('y:-',y)\n",
    "    width_of_image=x\n",
    "    height_of_image=y\n",
    "    print(0.5*width_of_image)\n",
    "    import numpy as np\n",
    "    a=int(0)\n",
    "    no_of_c=0\n",
    "    list_strings=[]\n",
    "    results  = []\n",
    "    print('no.of contours are ',len(cnts))\n",
    "    aspect_ratios=[]\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if h > 1 and w > 1:\n",
    "            roi=image[y:y+h,x:x+w]\n",
    "            predictable_img = cv2.resize(roi, (300,128))\n",
    "            a+=1\n",
    "\n",
    "            # Resize the image to the required size (64, 64)\n",
    "            test_image = cv2.resize(predictable_img, (64, 64))\n",
    "            test_image=np.expand_dims(test_image,axis=0)\n",
    "            if a==1:\n",
    "                plt.imshow(predictable_img,cmap='gray')\n",
    "\n",
    "            result=cnn.predict(test_image)\n",
    "\n",
    "            if result[0][0]==1:\n",
    "                  prediction='HW'\n",
    "            else:\n",
    "                  prediction='DT'\n",
    "\n",
    "            if prediction == 'HW':\n",
    "                if( y < 0.2 * height_of_image or y > 0.8 * height_of_image or w > width_of_image/1.5):\n",
    "                    continue\n",
    "                \n",
    "                else:\n",
    "                    S=\"\"\n",
    "                    no_of_c+=1\n",
    "                    #plt.imshow(predictable_img,cmap='gray')\n",
    "                    boxes=cv2.rectangle(image, (x, y), (x+w, y+h), (36, 255, 12), 2)\n",
    "                    predictable_img = cv2.cvtColor(predictable_img, cv2.COLOR_BGR2GRAY)\n",
    "                    print(predictable_img.shape)\n",
    "                    S=first1(predictable_img)\n",
    "                    list_strings.append(S)\n",
    "\n",
    "                    if no_of_c==3:\n",
    "                        rd_hw_img=predictable_img\n",
    "                        plt.imshow(rd_hw_img,cmap='gray')\n",
    "\n",
    "    print('no of handwritten contors are ',no_of_c)\n",
    "    st.image(boxes, caption='Bounding boxes image (OpenCV format)', use_column_width=True, channels='BGR')\n",
    "    print('a is ',a)\n",
    "    return list_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478bd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if uploaded_file is not None:\n",
    "    \n",
    "    # Load the image into OpenCV format\n",
    "    image_cv = load_image_into_cv2(uploaded_file)\n",
    "    \n",
    "    # Display the uploaded image using Streamlit\n",
    "    st.image(image_cv, caption='Uploaded Image (OpenCV format)', use_column_width=True, channels='BGR')\n",
    "    \n",
    "    # Define the border to be removed (example values)\n",
    "    top_border = 40\n",
    "    bottom_border = 40\n",
    "    left_border = 30\n",
    "    right_border = 30\n",
    "    \n",
    "    # Crop the image using numpy slicing\n",
    "    cropped_img = image_cv[top_border:image_cv.shape[0] - bottom_border, left_border:image_cv.shape[1] - right_border]\n",
    "    \n",
    "    #copying cropped image\n",
    "    image=cropped_img.copy()\n",
    "    base_image=image.copy()\n",
    "    \n",
    "    #grayscaling the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #blurring the image\n",
    "    blur = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "    \n",
    "    #thresholding the image\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    #kernel of image\n",
    "    kernal = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 2))\n",
    "    \n",
    "    #dilate the image\n",
    "    dilate = cv2.dilate(thresh, kernal, iterations=2)\n",
    "    \n",
    "    #finding the contours\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    cnts = sorted(cnts, key=lambda x: cv2.boundingRect(x)[0])\n",
    "    \n",
    "    list_strings_1=HWContours(cnts)\n",
    "    print(list_strings_1)\n",
    "    \n",
    "    \n",
    "    for l in range(len(list_strings_1)):\n",
    "        prediction=list_strings_1[l]\n",
    "        st.write(f\"Prediction: {prediction}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a5c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f07acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad2c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618a753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
